# Data Mining Notes

- 3 -> Definition
- 7: 
  - Model -> Decision Tree für Vorhersage um zu schauen ob eg. es sich lohnt einer Person Werbung zu schicken
  - 2 Teile, Modellieren dann in Produktion
- 9 (älteres Format)
  - Business Understanding -> Was wollen wir machen? Bilden Fragen
  - Data Understanding -> Geben die Daten die wir schon haben die Info her um die Fragen zu beantworten
  - Data Preparation -> Sind die Daten so wie wir denken (data wrangling)
  - Modelling -> Die Daten in ein Modell zu bringen, das dem Business Understanding hilft
  - Evaluation -> wie gut funktioniert es? Man hat metriken um zu schauen ob es gut ist
    - gibt dem Business zurück, visualisieren, etc. was ist passiert.
    - Kann sein dass es follow up gibt von dem Business Fachpersonen, und der Prozess beginnt von neuem
  -  Deployment -> wenn das Modell gut ist und es keine weiteren Fragen mehr gibt
-  16:
   -  Wenn zwei Vektoren aneinander gelegt werden, kann herausgefunden werden wie gross der Winkel dazwischen ist.
   -  Wenn zwei Vektoren in die gleiche Richtung zeigen -> 1, entgegengesetzt -> 1, rechtwiklig -> 0
-  19: Clustering
   -  Aufteilen in Gruppen die in irgendeiner Form ähnlich sind.
- 21:
  - Y unterschiedliche Datensätzte , das farbige ist was der algorythmus als ähnlich bezeichnen würde.
-  22: K-means algorithm
   -  **K** -> anzahl der punkte nach denen geclustert wird, wird irgendwie fest gelegt werden. Kann fix sein, eg.
      Kleidergrössen.
   -  Startpunkt komplett zufällig, der punkt bei dem alle punkte die dem ähnlich sind werden zugeordnet
   -  Dann werden mehrere Punkte hinzugefügt.
   -  Dann ortet man die punkte nach abstand, nimmt einen neuen zentroid beim mittelpunkt, und fügt neue punkte hinzu
   -  Es kann sein, dass die Punkte die Farbe wechseln, weil sie einem neuen Zentroid hinzugeordnet werden
   -  optimiert sich über die zeit, irgendwann bewegen die zentroiden sich nicht mehr. Dann kann gestoppt werden
   -  konvergiert nicht jedesmal zur selben lösung, hängt von der start position ab. Daher wird es meistens mehrmals laufen gelassen
-  24
   -  Idealerweise will man ein möglichst kleines K haben.
   -  Wie der quadrierte Abstand sich zu den Zentroiden verhält
   -  Je mehr cluster wir starten (k) desto kleiner ist die summer der quadratischen Distanzen
   -  Hier wenn wir bei K=3 nimmt der abstand nicht gross ab, also ist das ein erstes optimum.
- 26: DBSCAN
  - epsilon -> distanz zwischen zwei samples, max distanz um reachable zu sein
  - anzahl minimal points, wie viele punkte gegeben sein müssen um ein punkt als kern punkt zu zeichnen
  - Border points: erreichbar von den core points, aber selbst haben sie nicht genügend nachbarn um ein core point sein können.
  - Noise points: sind zu weit weg von irgendeinem punkt um reachable zu sein.
  - Als erstes schauen wir nur wo core points sein könnten. Wenn im epsilon radius keine eg. 4 punkte drinn sind, ist es kein core point.
  - Border points sind auch innerhalb einer cluster
  - Expansion, startet mit einem punkt und markiert alle punkte die innerhalb vom epsilon sind
  - Stärke ist, dass automatisch implizit über die definition von epsilon und min points outliers identifiziert werden können
  - Ziel: möchte eine einordnung machen um daten zusammen zufassen. Wie weit muss der Datensatz reduziert werden?
  - Werte Wahl sind abhängig von dichte von datensatz. Bei dichtem datensatz kann ein kleines epsilon gewählt werden.
  - 
