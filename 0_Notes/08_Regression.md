# Regression

- Wir können fast alles mit regressions rechnung machen
- Realität -> lateinische Buchstaben, modell welt ist griechisch
- 3: Simple Linear Regression Model: 1 input variabel und 1 output variable -> gerade linie
- 5: Realität
  - Extrem fälle sind selten
  - Daten gehen trichterförmig auseinander
  - Je mehr aufzufüllen desto grösser die streuung
  - Wenn wir eine gerade einfügen, menschen können gut abschätzen
  - Geht es durch 0? Was bedeutet es wenn es durch 0 geht oder nicht?
- 6: Modell Welt
  - beta steigung
  - Epsilon ist der fehler
  - Input x, y output
  - epsilon (fehler), gerade wird nicht exakt durch die punkte durchgehen, daher fehler hinzu (10 flaschen unterschiedliche zeit)
  - epsilon streuut um 0, wir wissen nicht wie viel es streuut (varianz)
  - Relative fehler (trichterförmige verteilung)
  - annahme fehler sind konstant
- 7: Es gibt verschiedene Modell Welte
  - Mechanistische Modelle: Physik, etc. fast alles lässt sich aus sachen ableiten (action reaktion, etc). Relativ stabil
  - Empirisch: Alkhohol und Krebsrisiko, gibt keine pyhsik formel die das erklärt. Sondern daten die den zusammenhang suggerieren. Relativ instabil. Wir suchen nach modellen. Welche variabeln sind signifikant. Hat das Körpergewicht einen einfluss? Welche variablen sind wirklich entscheidend?
- 8: Wir wollen eine vorhersage machen
  - Vorhersagen müssen mit dem vertrauensinterval versehen
  - In mechanische modelle gibt es oft variabeln die oft eine physikalische bedeutung haben. (strom, etc.)
  - Welche variablen sind signifikant?
  - Optimierung, wenn wir nach einem Wunschresultat suchen, werden wir schauen welche input variablen gut sind um das optimum zu erreichen.
- 9:
  - Regression -> die modell welt sollte die resultate der realen welt am besten passen
- 10:
  - beta 0 (hier nicht immer) -> y achsen abschnitt wenn x = 0 (oftmals nicht interessant, weil wir ja nicht interessiert sind wenn nichts passiert)
  - beta 0 ist vielleicht nicht klar definiert (zeit an dem angefangen wird zu messen)
  - der fehler können wir nicht schätzen, sondern nur wie sie streuut
- 11:
  - legen durch die datenpunkte die "best passende gerade" zu legen
  - die suchen wir so, dass wir den abstand zwischen dem realen y wert (punkt) zu dem y wert der auf der gerade liegt zu messen
  - die best passende gerade ist die bei denen alle abstände (betrag können negativ positiv sein) zusammengezählt möglichst klein.
  - Wir minimieren die summe der quadrate aller abstände. Wir haben dann eine gerade und haben parameter so lange bis die summe der quadrate minimal ist.
  - Wenn nur die summer angeschaut wird ist es schwierig, weil wir haben zwei parameter. Wie finde ich das optimum? -> lineare algebra
  - die summe der quadrate können wir uns als fläche vorstellen. Wir haben so eine senke. Die Senke finden wir in dem wir dem gradienten entlang nach unten gehen.
  - Im Minimum in der Senke hat es eine horizontale tangentialebene (die fläche wird nur einmal berührt)
- 12: Wir abgeleitet und setzten gleich 0 -> beobachtung, wir leiten nach beta 0 ab und beta 1. Sie sind linear und daher einfach auch wenn sie lange ist. Weil sie sauber ausgeklammert werden können
  - x werte kennen wir, egal wievile es sind. Die y werte sind auch bekannt. Dann können wir einfach nach den anderen auflösen.
- 13: die gleichungen sind bekannt, und es kann ausgerechnet werden
  - der fehler term haben wir nicht
- 14: Residual für den fehler term
  - messwert - fitteten wert -> es gibt so viele fehler wie beobachtungen. Im schnitt sind die fehler null
  - die gerade bei der die Fehler im schnitt null sind gibt dasselbe resultat wie minum der quadrate
  - summe aller kleinster quadrate (minus plus geht ja weg) ist error sum
  - hüte auf den buchstaben -> wenn ich der hypothese (griechisch) einen wert zuweise dan gibt es einen "Hut" (hat) auf die variabel
- in Python -> 08-Regression-notebooks/Example 7.1.1-7.4.2 Vending Machines (minimal).ipynb
  - Im summary output steht viel, wir konzentrieren uns jetzt auf die koeffizienten 
                    **coef**    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    **Intercept      3.3208**      1.371      2.422      0.024       0.484       6.157
    **Volume         2.1762** 

- 17: Jetzt fängt die arbeit an.
  - Analyse ob die antwort gut ist.
  - Kann das Model verwendet werden um eine vorhersage zu machen?
  - Wir haben angenommen, dass die varianz konstant ist.
  - Interpolation:
    - Ist gut
    - Wir machen prognosen für einen wert der innerhalb der messwerte sind (max 20 Flaschen gemessen, ich will einen wert für 15 haben)
  - Extrapolation:
    - ist heikel
    - 100 flaschen prognose, keine messwerte in diesem bereich
    - Veranstaltung, alles ist leer, müssen wir mehr leute anstellen um alle maschienen aufzufüllen. Dafür haben wir keine Messwerte. Können wir die gerade weiterziehen ausserhalb der Messwerte
- 18: Zusätzlich neue annahmen
  - Wir nehmen an, dass unsere fehler normalverteilt sind. Das haven wir vorher nicht gemacht.
  - Wir haben unsere Gerade, punkte die nahe sind, sind wahrscheinlich. Punkte die weit davon entfernt sind, sind unwahrscheinlich. -> Wir nehmen an dass die fehler in einer Normalverteilung sind. Machen wir damit das was folgt, handle bar ist.
  - Wir haben eine vending maschiene eine person füllt sie auf. Am nächsten tag mit gleichem elan. Ist immer gleich schnell beim auffüllen. Die geraden verändern sich etwas mit jeder neuen messung. Wir können alle steigungen zusammen nehmen und ein histogramm machen. Die verteilung der steigungen sind auch normalverteilt. Wir wissen auch die breite der Normalverteilung
  - Wenn die verteilung schmal ist dann ist die varianz klein, wenn die normalverteilung breit ist hat es eiine grosse varianz
  - Kleines Sxx
    - kleine streuung der messdaten
    - viel bewegung durch steigung
  - Grosses Sxx
    - grosse streuun der mess daten
    - kleine bewegung durch steigung
  - Wenn wir im labor sind wollen wir ein grosses Sxx sodass die gerade auf dem maximum stabil ist. Wenn wir zahlen empirische zahlen haben ist das vielleicht nicht möglich
- 19: Test statistic (werte die ich gemessen habe - annahme test (0 hypothese)) / (standard fehler)
- 20: P wert ausrechnen basierend auf dem statistischen test um zu wissen wie wahrscheinlich es ist
- 22: Per default kommt in python raus, ob die steigung auch 0 sein kann, nicht mein wert "2". Annahme, wenn ich keine flaschen auffüllen muss kann es keinen einfluss haben auf die output variabel.
-                  coef    std err          t      **P>|t|**      [0.025      0.975]
    ------------------------------------------------------------------------------
    Intercept      3.3208      1.371      2.422      **0.024**      0.484       6.157
    Volume         2.1762      0.124     17.546      **0.000**     1.920       2.433  
    kann die steigung 0 sein? -> nein weil **P>|t|** = 0.
    Wenn es 0 flaschen hat hat es hat einen einfluss

- 23: 
  - welcher wert ist der plausibelste wert? Die kleinste quadrate
  - Kann ein anderer Wert auch plausiebel sein -> Hypothesen test (ist 2 auf plausibel wenn ist 2.17 gemessen habe)
  - Welche werte sind überhaupt pausibel? -> vertrauensinterval
- 24: Vertrauensinterval
  - Alle werte die die 0 Hypothese erfüllen. Zwischen dem unteren und dem oberen kritischen wert (signifikanz niveau ist per default 5%)
  - Von - bis -> `[unterinterval grenze , oberinterval grenze]`
-                   coef    std err          t      P>|t|      **[0.025      0.975]**
    ------------------------------------------------------------------------------
    Intercept      3.3208      1.371      2.422      0.024     **0.484       6.157**
    Volume         2.1762      0.124     17.546      0.000     **1.920       2.433**
    
    Ist 2 Volume auch möglich? Ja es ist zwischen den zwei interval grenzen

- 25: Wie interpretiere ich den Vertrauensinterval?
- in der statistik machen wir fehler 1. art. Im durchschnitt liegt man 1 mal in 20 falsch
- 26: Wir wollen eine prognose machen
  - z.b. Wir haben ein Model für die Temperatur, prognose wert
  - Vertrauensinterval ist klein, wenn das modell gut ist (präzise)
  - Vertrauensinterval ist gross, wenn das modell sich nicht sicher ist (grosse mögliche temperatur)
- 27: -> `[wert auf der gerade (y hat) minus etwas , wert auf der gerade (y hat) plus etwas]`
  - sigma hat -> wie viel streuuen haben die werte auf der gerade
  - Vertrauensinterval ist grösser wenn sie mehr streuuen um die geraden
  - `x0` ist der neue wert den ich prognostizieren will
  - Die vertrauensintervale sind nicht linear, je weiter meine prognose ausserhalb der messwerte sind wird der vertrauensinterval grösser (also ungenauer)
- Prognosen heisst ihr fährt auto, während ihr in den Rückspiegel schaut. Ihr wisst wie die strasse hinter euch aussieht. Dann geht ihr nach vorne und fährt blind nach vorne in der annahme dass sie gleich ist wie nach vorne. Wie weit könnt ihr fahren um nicht von der strasse weg kommen? Umso kürzer desto besser.
- 32: Residual Analysis
  - Können wir das model noch verbessern?
  - Z.b. wäre es besser gewesen, wenn ich die input oder output variabel transformiert hätte. Z.b. den input logarithmieren.
  - 1. Es ist linear
  - 2. In der theorie ist es wahr.
  - 3. Der fehler ist konstanz. Daten die trichterförmig auseinandergehen ist nicht gut für das model
  - 4. Annahme dass die fehler keinen zusammenhang haben
  - 5. Die Fehler sind normalverteilt.
  - Es geht darum kann es noch besser gehen? Gibt ein anderes Model das besser ist?
- 34: Wir wollen explorative daten analyse machen. Wir wollen das Modell verbessern.
  - Das ganze geht rein graphisch, wir schauen bilder an, nicht mathematisch.
  - Das problem ist, wenn zwei personen bilder anschauen gibt es nicht daselbe resultat. Es ist abhängig von intuition und erfahrung. Es braucht auch domäne expertise. Eine verbindung zwischen den daten und der analyse. Wir müssen wissen in welchem gebiet wir darin sind.
- 36: wir haben ein exponentielles wachsumt. 
  - Wir können das nie mit einer geraden modellieren. 
  - Pressure -> Nicht lineral, A is linear, B ist nicht linear
  - Also müssen wir die input variabel transformieren, sodass wir eine gerade erhalten.
  - Wie transformieren wir sie?
  - Wenn wir das modell auf beiden seiten logarithmieren
  - ln(Pressure) ist gerade
- 37: gäbe es eine andere transformation die das besser machen könnte. 
  - Wir haben es logarithmiert, aber wir hätten auch auf beiden seiten die wurzel zienen können. Müssen wir sie anders transformieren?
  - Graphic 1 ist gut, wenn die input variabel maximal 2 ist. Am besten 1, dann ist es 2-D
  - Graphic 2: y achse ist dieselbe, x -> fitted values (das resultat). Wenn wir mehr als 3 Input variabeln haben, können wir wieder eine 2-D zeichnung machen. -> Gemessen vs. gefittet.
  - Die Punkte sollten möglichst nahe zu der Diagonale sein. Schauen wir die Graphic 2 an. Wie gut sind wir? -> Mass ist das *Bestimmtheitsmass* (R quadrat). Gemessen vs. gefittet. Es ist jedoch nur eine gute Aussage wenn wir wissen dass es um diese gerade streuut. R quadrat wie linear ist das verhältnis zwischen response und fit.
- 39: R2 ist nicht mehr gut wenn es nicht linear ist. 
  - Die Daten sind so konstruiert, dass alle nummern (r2, etc. sind identisch).
  - Nur durch die graphic sehen wir, dass das resultat bullshit ist.
  - Das r quadrat sagt nur etwas aus wenn wir in der 1. Situation sind.
  - Wie wissen wir in welchem plot wir sind? Wenn wir viele input variabeln haben, können wir nicht wissen in welchem plot wir sind.
  - Also wir brauchen etwas besseres als r quadrat
- 40: 3 plots welche besser sind als r quadrat
  - Haben wir gefährliche Abweichungen der 5 Annahmen (S. 32)
  - Wir können nur dem Vertrauensinterval trauen, wenn die 5 Annahmen erfüllt sind.
  - Wir müssen zuerst diese drei plots anschauen um zu wissen ob wir die resultate in der tabelle überhaupt etwas wert sind.
- 41: Blaue ist das residium, rot ist fitted
- 42: plotten wir dieses verhältnis
  - 1. Graphik es stimmt aber nicht gut, es sieht ein wenig gekrümmt aus. unten residual negativ oben positiv. Die krümmung ist nicht gut sichbar.
  - 2. Residual vs. gefitteten werte geplottet sehen wir etwas klarer
    - residuum 1. punkt und dann diestanz zu der linie. Wir sehen die abweichungen basierend auf den fitteten wert
    - Wir sehen es hat struktur drin. Das ist nicht gut. Die residuen sollten im schnitt überall 0 sein.
    - Die struktur zeigt, dass das model nicht gut ist. -> wieder zurück die transformierungen von input / output sollte neu gemacht werden.
- 43: wir haben nur den pressure logarithmiert.
  - Tukey Anscome zeight es hat weniger struktur, nicht keine. Keine exakte wisschenschaft, irgendwann müssen wir entscheiden. Wieviel struktur ist tollerierbar?
- 44: 
  - 2. Annahme, die fehler sind im mittel 0, das heisst
  - 1. Graph: ich glätte die daten. Nehme ein fenster innerhalb der fittet values und berechne das mittel. gibt einen punkt auf der roten linie. Schiebe das fenster erneut, neuer punkt. etc. Kleine fenstergrösse wird sehr kurvig. grosse grösse wird sehr gerade. jetzt mache ich ein gewichtetes mittel mit einer gauss kurve. Jetzt kann ich noch ein polynom 2. grades and die kurve anpassen. 
  - Rote kurve in jedem fenster sollte der schnitt 0 sein. Idealerweise sollte die rote kurve 0 sein. Reale welt, fast auf 0 ist gut. jetzt ist die frage wie viel weg von null ist gut?
  - 2. Graph: weitere 19 kurven. boot-strap verfahren. Ich habe einmal gemessen und ich mache 19 simulationen. Jetzt ist die frage ob meine messung gut zu der simulation passt. Für signifikanzniveau von 5% dann 19 mal. 1% signifikanz, 99 mal simulieren.
  - Vielleicht ist jedes Modell schlecht. Aber dann wissen wir dass es kein lineares modell ist. Dann gibt es nicht lineare modelle
- 47: Annahme die fehler haben die gleiche varianz. In realität die fehler waren trichterförmig bei den Flaschen. Das darf nicht sein.
- 47: scale location, nur der betrag des residium wird aufgezeigt. Ein guter ist, wenn es gerade ist. Die varianz ist nicht gerade -> also ist es klar. Hier ist die sitatuion ziemlich krass und und wir wissen dass die modell annahme ist verletzt, die tabelle mit den p werte können weggeworfen werden.
- 49: fehler sind normalverteilt -> q-q plot
  - wieder 19 normal q-q plots. Die frage ist mein datensatz da drin. In diesem fall ja.
  - ist es normalverteilt?
- Wir müssen etwas mit etwas anderem verteilen. Wir müssen immer wissen wie viel es streuut.
- 51: wir haben noch mehr, wenn die plots nicht gut sind müssen wir herausfinden wieso es nicht gut ist.
  - Die daten haben wir, die können wir nicht verändern. Wir können höchstens das modell verändern.
  - Wir haben fast immer eine trichterförmige varianz. Das löst man dass man die zielgrösse logarithmiert. dann ist der trichter weg.
  - Problem mit ausreisser
  - problem dass q-q plot, dass es werte hat die oft vorkommen. Die normalverteilung hat fast keinen spielraum für extreme werte. In der realität haben wir mehr extreme werte als es die normalverteilung zulässt. Indem wir es logarithmieren können wir auch die extremen werten kleiner machen.
- 52: in der regel werden alle graphen gleichzeitig angeschaut.
- 53: wenn etwas nicht gut ist, kann es mit Tueky meistens geflickt werden.
  - log wenn nicht gut ist -> wurzel wenn nicht gut ist -> etc. 
  - In physik ist teilweise vorgeschrieben / klar welche transformation gemacht werden sollte
- 54: 
  - 1: der datensatz ist nicht falsch aber ein x wert ist falsch. Das macht die kurve komplett kaputt
  - 2: ein anderer ausreisser. wenn der ausreisser nicht da wäre, hätten wir keine gute gerade.
  - Ausreissen sind beliebig schwierig zu identifizieren
- Mittelwert hat ein bruchpunkt von einem Datenpunkt (einer kann es zerstören). Regressionsrechnungen sind voll mit mittelwerten, daher extrem anfällig auf ausreisser. Auch neuronale netzwerke. Also die Daten müssen unbeding vorher angeschaut werden.
- 55: Ausreisser seht man nicht an den linien. Sondern am scatterplot. Hier ist 37 heikel. nachschauen was passiert ist
- Die 19 simulationen können mit keinem package gemacht werden das er kennt. R hat packages die das machen.
- 58: annahme die fehler sind zufällig. Das ist schwierig nachzuvollziehen. Datum immer aufnehmen um zu wissen ob es eine zeitliche abhängigkeit hat.
- 59: 1. schwingung über zeit, 3. zu stark mit der zeit korreliert. es sollte ungefähr aussehen wie in der mitt
  - unten 3. Wir messen das residium von heute gegen morgen. -> wenn das residium heute gross ist dann ist es morgen auch gross. 1. Wenn es heute gross ist ist es morgen klein. In der mitt sehen wir nur noise
  - Wenn wir eine zeitliche korrelation haben, dann müssen zeitreihen analyse gemacht werden. Es ist nicht mehr regression
- Wenn die plots etwa gut sind, dann dürfen wir dem p wert und dem vertrauensinterval vertrauen. Also das modell muss so ge-tweaked werden dass die plots gut aussehen.

## Multiple Lineare Regression (62)

- Unterschied zu Simpel, wir haben mehr als eine input variabel
- wir haben selten bis nie nur eine erklärende variabel
- 62:
  - x=1 bis x=m -> m ist anzahl erklärende variabeln. "m" sollte klein sein (max 100)
  - wenn n (anzahl messungen) kleiner ist als m (erklärende variabeln) wir python einen fehler werfen
  - Wri legen nicht mehr eine gerade in die messungen sondern eine ebene rein.
  - k ist die Anzahl slopes
- Kleinste quadrate, wieder residuen, quadrieren sie (das fähnchen bleibt zwei dimensional immer quadrate) und schieben wieder die ebene herum bis die quadrätchen am kleinsten sind. Wir haben drei variablen die wir verschieben und dann suchen wir das minimum.
- 63:
  - Tunnel bauen, sprengen im boden und in den häuser wurde vibration gemessen
  - Häuser sollten nicht beschädigt werden (Schäden wenn Vibration grösser 12)
  - Wussten, die Ladung, distanz zu messort und dann vibration
  - Physik überlegen -> Vibration ist proportional zu? Ungf. -> 1 / (Distanz quadriert)
  - Ladung hat auch einen einfluss -> Ladung mal ( 1/ (Distanz mal Distanz)) annahme gesetzt
  - V ~ C mal (1/D2)
  - Wir logarithmieren es log(V) ~ log(C) + log(1/D2)
  - Ich habe ein modell vielleicht beschreibt mir das Modell den Datensatz?
- 64:
  - Wir bekommen wir die beta nummern heraus?
- 65:
  - Matrix Notation der gleichungen
- 66:
  - Matrix, ich will jedes einzige epsilon in der spalten matrize quadrieren und summieren
  - Ich variiere die betas um die summe der epsilon im quadrat zu minimieren
  - Wir lösen sie auf nach 0 -> weil wir suchen die horizontale tangente
- 67: Was muss ich machen um y hat zu erhalten?
  - messwerte mal input werte gibt y hat (Fitted Values)
  - Residual -> gemessenen minus gefitted
  - Beta 0 ist die konstante (wo es durch 0 geht)
- 68:
  - Für alle koefizienten können wir vertrauensinterval, hypothesen test, etc. machen, wir rechnen es einfach mit matrizen aber in python merkt man das nicht
- In scripts "Explicit formula" ist wie es "von hand" gerechnet. 
- Formel -> "Output hängt ab von var1 + var2" -> `output ~ var1 + var2 + var3` ist die veränderte formel
